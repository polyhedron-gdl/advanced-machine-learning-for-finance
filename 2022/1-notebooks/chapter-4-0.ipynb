{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Volatility Movements  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our next application of neural networks, some extra background  about derivatives is required.  The Black‚àíScholes‚àíMerton model relates an option price to the asset price, strike price, dividend yield, riskfree interest rate, time to maturity, and volatility. All of these quantities  are known by analysts except volatility. This means that the Black‚àíScholes‚àíMerton model in effect provides a one-to-one mapping  of volatility to the price of an option. The volatility that gives the market  price of an option is known as the implied volatility. The moneyness of an option is a measure of how likely an option is to  be exercised. One measure of the moneyness of an option that is frequently used by traders is delta. This is the sensitivity of the option‚Äôs  price to the price of the underlying asset. For the Black‚àíScholes‚àíMerton  model given earlier, the delta of a call option is $ùëí^{‚àíùëûùëáùëÅ(ùëë_1)}$. For a call  option that is highly unlikely to be exercised (high strike price), delta is  close to zero. As the option become more likely to be exercised (i.e., the  strike price is reduced), delta increases. When the option is almost certain to be exercised delta is close to one.  The volatility surface gives the implied volatility as a function of the  moneyness and time to maturity. If Black‚àíScholes‚àíMerton was a perfect model for the pricing of options in the market, the implied volatilities for all options would be the same and would never change. In practice, the model is far from perfect and the volatility surface is used by  analysts to monitor the market.  \n",
    "\n",
    "Many different non-linear  shapes for the surface are observed in practice. When the price of an  asset declines, all implied volatilities calculated from options on the asset tend to increase, and vice versa. However, the implied volatilities do  not all change by the same amount. This leads to many variations in the  pattern of implied volatilities.  Understanding how the volatility surface moves is important for a  number of reasons:\n",
    "\n",
    "- It can help a trader hedge exposures more precisely \n",
    "\n",
    "- It can help a quant determine a more sophisticated model reflecting how options are priced by the market.  \n",
    "\n",
    "- It can help a trader adjust implied volatilities in a market where  asset prices are changing fast. \n",
    "\n",
    "A neural network is a natural tool for using empirical data to model volatility surface movements. We will illustrate how it can be used in what  follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This program takes about 60 minutes to run\n",
    "#Loading Package\n",
    "import os\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(100)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data consists of call options on the S&P 500 between 2014 and  2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data\\\\Implied_Volatility_Data_vFinal.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15272\\3469002544.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load raw data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mDATA_FOLDER\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./data'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_FOLDER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Implied_Volatility_Data_vFinal.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# check the raw data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Size of the dataset (row, col): \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data\\\\Implied_Volatility_Data_vFinal.csv'"
     ]
    }
   ],
   "source": [
    "# load raw data\n",
    "DATA_FOLDER = './data'\n",
    "raw = pd.read_csv(os.path.join(DATA_FOLDER, 'Implied_Volatility_Data_vFinal.csv'))\n",
    "# check the raw data\n",
    "print(\"Size of the dataset (row, col): \", raw.shape)\n",
    "raw.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the 3 variables for Regression Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are  three features:  \n",
    "\n",
    "- The return on the S&P 500 from one day to the next (i.e., increase in S&P 500 divided by its level)  \n",
    "\n",
    "- The time to maturity  \n",
    "\n",
    "- The delta of the option  The target is the change in the implied volatility. \n",
    "\n",
    "The objective is to  minimize the mean squared error between the predicted change in the  implied volatility and the actual change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In constructing a machine learning model, it is always useful to have  a simpler model as a benchmark. For this application, we can use the  following model:  \n",
    "\n",
    "$$\\text{Expected change in implied volatility} = R \\frac{a+b\\Delta + c \\Delta^2}{\\sqrt{T}}$$\n",
    "\n",
    "where $R$ is the return on the asset (= change in price divided by initial  price), $T$ is the option‚Äôs time to maturity, $\\Delta$ is the delta measure of the  option‚Äôs moneyness, and $a$, $b$, and $c$ are constants. This model was suggested by Hull and White (2017) and is quite popular with practitioner. The $a$, $b$, and $c$ can be estimated by regressing implied volatility  changes against $R/\\sqrt{ùëá}$, $R\\Delta/\\sqrt{T}$, and $R\\Delta^2/\\sqrt{T}$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15272\\3497248120.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# construct the 3 variables for regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SPX Return'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time to Maturity in Year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SPX Return'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time to Maturity in Year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Delta'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x3'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Delta'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'raw' is not defined"
     ]
    }
   ],
   "source": [
    "# construct the 3 variables for regression\n",
    "raw['x1'] = raw['SPX Return'] / np.sqrt(raw['Time to Maturity in Year'])\n",
    "raw['x2'] = raw['SPX Return'] / np.sqrt(raw['Time to Maturity in Year']) * raw['Delta']\n",
    "raw['x3'] = raw['x2'] * raw['Delta']\n",
    "\n",
    "# Put the X and Y variable in data frame for regression\n",
    "y = raw['Implied Volatility Change']\n",
    "X = raw[['x1', 'x2', 'x3','SPX Return','Time to Maturity in Year','Delta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into training set and test set(note that random seed is set)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=100)\n",
    "\n",
    "# Divide training set into training and validation set\n",
    "X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.25,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features based on Z-Score\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_vals = scaler.transform(X_val)\n",
    "X_scaled_test = scaler.transform(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_val = np.asarray(y_val)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (MSE): 7.423167462421238e-05\n"
     ]
    }
   ],
   "source": [
    "# Run the regression on the training data\n",
    "lr = LinearRegression(fit_intercept=False)\n",
    "lr.fit(X_scaled_train[:,:3], y_train)\n",
    "\n",
    "# Get the prediction\n",
    "y_pred = lr.predict(X_scaled_test[:,:3])\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print('Test loss (MSE):', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 941\n",
      "Trainable params: 941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create ML Model\n",
    "# Sequential function allows you to define your Neural Network in sequential order\n",
    "# Within Sequential, use Dense function to define number of nodes, activation function and other related parameters \n",
    "# For more information regrading to activation functoin, please refer to https://keras.io/activations/\n",
    "model = keras.models.Sequential([Dense(20,activation = \"sigmoid\",input_shape = (3,)),\n",
    "                                 Dense(20,activation = \"sigmoid\"),Dense(20,activation = \"sigmoid\"),\n",
    "                                Dense(1)])\n",
    "\n",
    "# Model summary function shows what you created in the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complie function allows you to choose your measure of loss and optimzer\n",
    "# For other optimizer, please refer to https://keras.io/optimizers/\n",
    "model.compile(loss = \"mse\",optimizer = \"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint function is used here to periodically save a copy of the model. \n",
    "# Currently it is set to save the best performing model\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"implied_vol_model_vFinal.h5\",save_best_only = True)\n",
    "\n",
    "# Early stopping allows you to stop your training early if no improvment is shown after cerain period\n",
    "# Currently it is set at if no improvement occured in 1000 epochs, at the stop the model will also revert back to the best weight\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 1000,restore_best_weights = True)\n",
    "\n",
    "# Remark: checkpoint could be redundant here as early stopping function can also help restoring to the best weight\n",
    "# We put both here just to illustrate different ways to keep the best model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "590/590 [==============================] - 2s 2ms/step - loss: 0.0798 - val_loss: 8.5765e-05\n",
      "Epoch 2/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.4348e-05 - val_loss: 8.5045e-05\n",
      "Epoch 3/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.4596e-05 - val_loss: 8.4279e-05\n",
      "Epoch 4/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.2241e-05 - val_loss: 8.3305e-05\n",
      "Epoch 5/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1264e-05 - val_loss: 8.2771e-05\n",
      "Epoch 6/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7646e-05 - val_loss: 8.3964e-05\n",
      "Epoch 7/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.9252e-05 - val_loss: 8.1792e-05\n",
      "Epoch 8/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7308e-05 - val_loss: 8.0802e-05\n",
      "Epoch 9/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8445e-05 - val_loss: 8.0680e-05\n",
      "Epoch 10/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8897e-05 - val_loss: 8.2996e-05\n",
      "Epoch 11/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0097e-05 - val_loss: 8.0869e-05\n",
      "Epoch 12/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.2853e-05 - val_loss: 8.0616e-05\n",
      "Epoch 13/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0582e-05 - val_loss: 8.0381e-05\n",
      "Epoch 14/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1605e-05 - val_loss: 8.0177e-05\n",
      "Epoch 15/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.4813e-05 - val_loss: 9.1003e-05\n",
      "Epoch 16/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.2848e-05 - val_loss: 7.9714e-05\n",
      "Epoch 17/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.5955e-05 - val_loss: 1.0317e-04\n",
      "Epoch 18/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.3490e-05 - val_loss: 7.9765e-05\n",
      "Epoch 19/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1122e-05 - val_loss: 8.3931e-05\n",
      "Epoch 20/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.5218e-05 - val_loss: 7.9995e-05\n",
      "Epoch 21/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.9672e-05 - val_loss: 7.9110e-05\n",
      "Epoch 22/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0587e-05 - val_loss: 8.3057e-05\n",
      "Epoch 23/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0059e-05 - val_loss: 7.9133e-05\n",
      "Epoch 24/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.4132e-05 - val_loss: 8.9097e-05\n",
      "Epoch 25/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8844e-05 - val_loss: 8.8249e-05\n",
      "Epoch 26/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1643e-05 - val_loss: 8.2180e-05\n",
      "Epoch 27/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.8320e-05 - val_loss: 8.0719e-05\n",
      "Epoch 28/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 8.1904e-05 - val_loss: 8.6301e-05\n",
      "Epoch 29/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 8.2402e-05 - val_loss: 7.8567e-05\n",
      "Epoch 30/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.6463e-05 - val_loss: 9.2232e-05\n",
      "Epoch 31/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 8.0644e-05 - val_loss: 8.1581e-05\n",
      "Epoch 32/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 8.0344e-05 - val_loss: 7.8857e-05\n",
      "Epoch 33/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.3288e-05 - val_loss: 7.9010e-05\n",
      "Epoch 34/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.2043e-05 - val_loss: 8.1006e-05\n",
      "Epoch 35/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1798e-05 - val_loss: 8.0412e-05\n",
      "Epoch 36/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.2182e-05 - val_loss: 8.9243e-05\n",
      "Epoch 37/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1145e-05 - val_loss: 8.8923e-05\n",
      "Epoch 38/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1015e-05 - val_loss: 8.7382e-05\n",
      "Epoch 39/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.2795e-05 - val_loss: 7.8396e-05\n",
      "Epoch 40/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1669e-05 - val_loss: 1.0753e-04\n",
      "Epoch 41/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.3063e-05 - val_loss: 9.2280e-05\n",
      "Epoch 42/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0933e-05 - val_loss: 8.3530e-05\n",
      "Epoch 43/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.9415e-05 - val_loss: 8.4355e-05\n",
      "Epoch 44/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.3371e-05 - val_loss: 7.9734e-05\n",
      "Epoch 45/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0611e-05 - val_loss: 9.4206e-05\n",
      "Epoch 46/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1703e-05 - val_loss: 8.1586e-05\n",
      "Epoch 47/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7714e-05 - val_loss: 8.3469e-05\n",
      "Epoch 48/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0512e-05 - val_loss: 9.3937e-05\n",
      "Epoch 49/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0137e-05 - val_loss: 8.0147e-05\n",
      "Epoch 50/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1419e-05 - val_loss: 1.0893e-04\n",
      "Epoch 51/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.4660e-05 - val_loss: 7.9267e-05\n",
      "Epoch 52/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1483e-05 - val_loss: 8.0228e-05\n",
      "Epoch 53/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.2321e-05 - val_loss: 1.1578e-04\n",
      "Epoch 54/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.4647e-05 - val_loss: 8.1518e-05\n",
      "Epoch 55/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.2666e-05 - val_loss: 1.0820e-04\n",
      "Epoch 56/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0468e-05 - val_loss: 7.8682e-05\n",
      "Epoch 57/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0917e-05 - val_loss: 7.8114e-05\n",
      "Epoch 58/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.4759e-05 - val_loss: 8.9602e-05\n",
      "Epoch 59/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8482e-05 - val_loss: 8.1546e-05\n",
      "Epoch 60/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8039e-05 - val_loss: 8.7193e-05\n",
      "Epoch 61/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8754e-05 - val_loss: 7.9588e-05\n",
      "Epoch 62/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8249e-05 - val_loss: 7.8931e-05\n",
      "Epoch 63/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6253e-05 - val_loss: 1.3086e-04\n",
      "Epoch 64/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.2511e-05 - val_loss: 8.5750e-05\n",
      "Epoch 65/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.9927e-05 - val_loss: 8.9163e-05\n",
      "Epoch 66/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 7.8239e-05 - val_loss: 8.9302e-05\n",
      "Epoch 67/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.3745e-05 - val_loss: 7.8406e-05\n",
      "Epoch 68/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.9628e-05 - val_loss: 8.0124e-05\n",
      "Epoch 69/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1530e-05 - val_loss: 7.8869e-05\n",
      "Epoch 70/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6866e-05 - val_loss: 8.2535e-05\n",
      "Epoch 71/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0054e-05 - val_loss: 7.7463e-05\n",
      "Epoch 72/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1534e-05 - val_loss: 7.7637e-05\n",
      "Epoch 73/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0293e-05 - val_loss: 7.7378e-05\n",
      "Epoch 74/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0871e-05 - val_loss: 8.2020e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8760e-05 - val_loss: 7.9877e-05\n",
      "Epoch 76/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8629e-05 - val_loss: 7.7479e-05\n",
      "Epoch 77/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7186e-05 - val_loss: 7.8125e-05\n",
      "Epoch 78/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0028e-05 - val_loss: 7.8601e-05\n",
      "Epoch 79/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7584e-05 - val_loss: 8.7269e-05\n",
      "Epoch 80/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.2187e-05 - val_loss: 8.8295e-05\n",
      "Epoch 81/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0525e-05 - val_loss: 8.4616e-05\n",
      "Epoch 82/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.9263e-05 - val_loss: 7.8880e-05\n",
      "Epoch 83/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8577e-05 - val_loss: 1.2007e-04\n",
      "Epoch 84/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.9761e-05 - val_loss: 8.0674e-05\n",
      "Epoch 85/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8142e-05 - val_loss: 7.7553e-05\n",
      "Epoch 86/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7349e-05 - val_loss: 8.4692e-05\n",
      "Epoch 87/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1097e-05 - val_loss: 8.4098e-05\n",
      "Epoch 88/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.9395e-05 - val_loss: 9.1718e-05\n",
      "Epoch 89/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.2562e-05 - val_loss: 7.9851e-05\n",
      "Epoch 90/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8443e-05 - val_loss: 8.0971e-05\n",
      "Epoch 91/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5894e-05 - val_loss: 7.8489e-05\n",
      "Epoch 92/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0246e-05 - val_loss: 1.1130e-04\n",
      "Epoch 93/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8541e-05 - val_loss: 7.6350e-05\n",
      "Epoch 94/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8271e-05 - val_loss: 7.6234e-05\n",
      "Epoch 95/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8254e-05 - val_loss: 8.0715e-05\n",
      "Epoch 96/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1032e-05 - val_loss: 8.0174e-05\n",
      "Epoch 97/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 7.8147e-05 - val_loss: 7.7892e-05\n",
      "Epoch 98/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 7.7658e-05 - val_loss: 8.9539e-05\n",
      "Epoch 99/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1503e-05 - val_loss: 9.2291e-05\n",
      "Epoch 100/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 8.1974e-05 - val_loss: 7.9509e-05\n",
      "Epoch 101/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 7.7869e-05 - val_loss: 7.9253e-05\n",
      "Epoch 102/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 7.5594e-05 - val_loss: 8.3333e-05\n",
      "Epoch 103/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 7.6297e-05 - val_loss: 7.6273e-05\n",
      "Epoch 104/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6036e-05 - val_loss: 7.9823e-05\n",
      "Epoch 105/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5713e-05 - val_loss: 7.5876e-05\n",
      "Epoch 106/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3647e-05 - val_loss: 7.9553e-05\n",
      "Epoch 107/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5942e-05 - val_loss: 7.6900e-05\n",
      "Epoch 108/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6289e-05 - val_loss: 8.6151e-05\n",
      "Epoch 109/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7601e-05 - val_loss: 9.7719e-05\n",
      "Epoch 110/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7605e-05 - val_loss: 7.5629e-05\n",
      "Epoch 111/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7380e-05 - val_loss: 7.5445e-05\n",
      "Epoch 112/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8042e-05 - val_loss: 7.7983e-05\n",
      "Epoch 113/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3626e-05 - val_loss: 7.5218e-05\n",
      "Epoch 114/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.9921e-05 - val_loss: 7.6469e-05\n",
      "Epoch 115/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6214e-05 - val_loss: 7.7569e-05\n",
      "Epoch 116/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7988e-05 - val_loss: 8.8381e-05\n",
      "Epoch 117/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8935e-05 - val_loss: 8.5528e-05\n",
      "Epoch 118/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.9290e-05 - val_loss: 7.5612e-05\n",
      "Epoch 119/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7737e-05 - val_loss: 7.5261e-05\n",
      "Epoch 120/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7919e-05 - val_loss: 7.9276e-05\n",
      "Epoch 121/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7217e-05 - val_loss: 7.9215e-05\n",
      "Epoch 122/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6969e-05 - val_loss: 7.5918e-05\n",
      "Epoch 123/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6335e-05 - val_loss: 7.6200e-05\n",
      "Epoch 124/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5338e-05 - val_loss: 1.0211e-04\n",
      "Epoch 125/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6425e-05 - val_loss: 7.6653e-05\n",
      "Epoch 126/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8210e-05 - val_loss: 7.5160e-05\n",
      "Epoch 127/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1182e-05 - val_loss: 7.5772e-05\n",
      "Epoch 128/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6581e-05 - val_loss: 8.7369e-05\n",
      "Epoch 129/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8687e-05 - val_loss: 8.0140e-05\n",
      "Epoch 130/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7969e-05 - val_loss: 7.5112e-05\n",
      "Epoch 131/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8538e-05 - val_loss: 7.4798e-05\n",
      "Epoch 132/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8776e-05 - val_loss: 7.5052e-05\n",
      "Epoch 133/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0516e-05 - val_loss: 7.4953e-05\n",
      "Epoch 134/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6326e-05 - val_loss: 7.5951e-05\n",
      "Epoch 135/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0752e-05 - val_loss: 8.0807e-05\n",
      "Epoch 136/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8905e-05 - val_loss: 8.3412e-05\n",
      "Epoch 137/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.9717e-05 - val_loss: 8.0232e-05\n",
      "Epoch 138/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6333e-05 - val_loss: 7.4753e-05\n",
      "Epoch 139/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7263e-05 - val_loss: 7.7407e-05\n",
      "Epoch 140/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7885e-05 - val_loss: 7.7504e-05\n",
      "Epoch 141/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3691e-05 - val_loss: 7.5174e-05\n",
      "Epoch 142/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6888e-05 - val_loss: 8.2721e-05\n",
      "Epoch 143/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7516e-05 - val_loss: 7.4860e-05\n",
      "Epoch 144/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2860e-05 - val_loss: 9.3986e-05\n",
      "Epoch 145/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.1519e-05 - val_loss: 7.5514e-05\n",
      "Epoch 146/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3560e-05 - val_loss: 8.5094e-05\n",
      "Epoch 147/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6517e-05 - val_loss: 7.5721e-05\n",
      "Epoch 148/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7031e-05 - val_loss: 7.5613e-05\n",
      "Epoch 149/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 7.7646e-05 - val_loss: 8.2674e-05\n",
      "Epoch 150/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6830e-05 - val_loss: 7.7024e-05\n",
      "Epoch 151/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8921e-05 - val_loss: 7.4554e-05\n",
      "Epoch 152/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7509e-05 - val_loss: 7.4821e-05\n",
      "Epoch 153/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6908e-05 - val_loss: 7.6988e-05\n",
      "Epoch 154/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 8.0011e-05 - val_loss: 7.4526e-05\n",
      "Epoch 155/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7735e-05 - val_loss: 8.9050e-05\n",
      "Epoch 156/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5946e-05 - val_loss: 7.5028e-05\n",
      "Epoch 157/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7224e-05 - val_loss: 7.5389e-05\n",
      "Epoch 158/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6846e-05 - val_loss: 7.6634e-05\n",
      "Epoch 159/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6981e-05 - val_loss: 8.0960e-05\n",
      "Epoch 160/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5361e-05 - val_loss: 7.5629e-05\n",
      "Epoch 161/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7345e-05 - val_loss: 7.4940e-05\n",
      "Epoch 162/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3892e-05 - val_loss: 7.8991e-05\n",
      "Epoch 163/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7345e-05 - val_loss: 7.5475e-05\n",
      "Epoch 164/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5135e-05 - val_loss: 7.4931e-05\n",
      "Epoch 165/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6502e-05 - val_loss: 7.7660e-05\n",
      "Epoch 166/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8349e-05 - val_loss: 7.6018e-05\n",
      "Epoch 167/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4782e-05 - val_loss: 7.4807e-05\n",
      "Epoch 168/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8639e-05 - val_loss: 7.4590e-05\n",
      "Epoch 169/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7509e-05 - val_loss: 7.6204e-05\n",
      "Epoch 170/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6627e-05 - val_loss: 7.4695e-05\n",
      "Epoch 171/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7975e-05 - val_loss: 7.4608e-05\n",
      "Epoch 172/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6750e-05 - val_loss: 7.4824e-05\n",
      "Epoch 173/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4627e-05 - val_loss: 7.5216e-05\n",
      "Epoch 174/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7078e-05 - val_loss: 7.4159e-05\n",
      "Epoch 175/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2900e-05 - val_loss: 7.6465e-05\n",
      "Epoch 176/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8191e-05 - val_loss: 7.5668e-05\n",
      "Epoch 177/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6789e-05 - val_loss: 8.1198e-05\n",
      "Epoch 178/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7448e-05 - val_loss: 7.6225e-05\n",
      "Epoch 179/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.9211e-05 - val_loss: 7.5400e-05\n",
      "Epoch 180/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8042e-05 - val_loss: 7.5451e-05\n",
      "Epoch 181/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3768e-05 - val_loss: 7.4447e-05\n",
      "Epoch 182/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8144e-05 - val_loss: 7.5794e-05\n",
      "Epoch 183/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4063e-05 - val_loss: 8.9685e-05\n",
      "Epoch 184/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8611e-05 - val_loss: 7.6070e-05\n",
      "Epoch 185/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4143e-05 - val_loss: 7.4224e-05\n",
      "Epoch 186/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4073e-05 - val_loss: 7.6402e-05\n",
      "Epoch 187/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6434e-05 - val_loss: 7.4788e-05\n",
      "Epoch 188/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5786e-05 - val_loss: 7.4487e-05\n",
      "Epoch 189/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6053e-05 - val_loss: 9.0937e-05\n",
      "Epoch 190/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6012e-05 - val_loss: 7.8104e-05\n",
      "Epoch 191/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3147e-05 - val_loss: 7.5577e-05\n",
      "Epoch 192/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4381e-05 - val_loss: 7.6178e-05\n",
      "Epoch 193/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4928e-05 - val_loss: 7.4900e-05\n",
      "Epoch 194/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5049e-05 - val_loss: 7.4771e-05\n",
      "Epoch 195/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5181e-05 - val_loss: 9.1935e-05\n",
      "Epoch 196/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5882e-05 - val_loss: 7.5387e-05\n",
      "Epoch 197/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5512e-05 - val_loss: 7.6002e-05\n",
      "Epoch 198/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5721e-05 - val_loss: 7.4618e-05\n",
      "Epoch 199/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8588e-05 - val_loss: 8.1189e-05\n",
      "Epoch 200/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.9678e-05 - val_loss: 7.4278e-05\n",
      "Epoch 201/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4921e-05 - val_loss: 7.7346e-05\n",
      "Epoch 202/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6587e-05 - val_loss: 7.3973e-05\n",
      "Epoch 203/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6964e-05 - val_loss: 7.4781e-05\n",
      "Epoch 204/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1491e-05 - val_loss: 8.3643e-05\n",
      "Epoch 205/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8119e-05 - val_loss: 7.4259e-05\n",
      "Epoch 206/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5709e-05 - val_loss: 7.5641e-05\n",
      "Epoch 207/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5337e-05 - val_loss: 7.5354e-05\n",
      "Epoch 208/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5879e-05 - val_loss: 9.6407e-05\n",
      "Epoch 209/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4098e-05 - val_loss: 7.5988e-05\n",
      "Epoch 210/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7750e-05 - val_loss: 7.6919e-05\n",
      "Epoch 211/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4359e-05 - val_loss: 8.4565e-05\n",
      "Epoch 212/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4778e-05 - val_loss: 7.6679e-05\n",
      "Epoch 213/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4790e-05 - val_loss: 7.4007e-05\n",
      "Epoch 214/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4923e-05 - val_loss: 7.4093e-05\n",
      "Epoch 215/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8519e-05 - val_loss: 7.5131e-05\n",
      "Epoch 216/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4515e-05 - val_loss: 9.5656e-05\n",
      "Epoch 217/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7228e-05 - val_loss: 7.3866e-05\n",
      "Epoch 218/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4775e-05 - val_loss: 7.3980e-05\n",
      "Epoch 219/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4939e-05 - val_loss: 9.2335e-05\n",
      "Epoch 220/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8379e-05 - val_loss: 8.2059e-05\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6136e-05 - val_loss: 8.5376e-05\n",
      "Epoch 222/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4858e-05 - val_loss: 7.4452e-05\n",
      "Epoch 223/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3095e-05 - val_loss: 7.4320e-05\n",
      "Epoch 224/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7127e-05 - val_loss: 7.4729e-05\n",
      "Epoch 225/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6301e-05 - val_loss: 7.4869e-05\n",
      "Epoch 226/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4317e-05 - val_loss: 7.4626e-05\n",
      "Epoch 227/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1870e-05 - val_loss: 7.5687e-05\n",
      "Epoch 228/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6220e-05 - val_loss: 7.4441e-05\n",
      "Epoch 229/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5658e-05 - val_loss: 7.3701e-05\n",
      "Epoch 230/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5569e-05 - val_loss: 7.9237e-05\n",
      "Epoch 231/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5763e-05 - val_loss: 7.4173e-05\n",
      "Epoch 232/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5084e-05 - val_loss: 7.3996e-05\n",
      "Epoch 233/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5713e-05 - val_loss: 8.3528e-05\n",
      "Epoch 234/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5316e-05 - val_loss: 7.4231e-05\n",
      "Epoch 235/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4084e-05 - val_loss: 7.4577e-05\n",
      "Epoch 236/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5361e-05 - val_loss: 8.9109e-05\n",
      "Epoch 237/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5293e-05 - val_loss: 7.3777e-05\n",
      "Epoch 238/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4171e-05 - val_loss: 7.5231e-05\n",
      "Epoch 239/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3161e-05 - val_loss: 7.4750e-05\n",
      "Epoch 240/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4787e-05 - val_loss: 7.4893e-05\n",
      "Epoch 241/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4059e-05 - val_loss: 7.8631e-05\n",
      "Epoch 242/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6934e-05 - val_loss: 7.3713e-05\n",
      "Epoch 243/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3663e-05 - val_loss: 7.4121e-05\n",
      "Epoch 244/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8871e-05 - val_loss: 7.7406e-05\n",
      "Epoch 245/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5625e-05 - val_loss: 7.3626e-05\n",
      "Epoch 246/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4904e-05 - val_loss: 7.4300e-05\n",
      "Epoch 247/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5707e-05 - val_loss: 7.5447e-05\n",
      "Epoch 248/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5343e-05 - val_loss: 7.7338e-05\n",
      "Epoch 249/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6557e-05 - val_loss: 7.4666e-05\n",
      "Epoch 250/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5702e-05 - val_loss: 8.0109e-05\n",
      "Epoch 251/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3487e-05 - val_loss: 7.8919e-05\n",
      "Epoch 252/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7234e-05 - val_loss: 7.4691e-05\n",
      "Epoch 253/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5329e-05 - val_loss: 7.3966e-05\n",
      "Epoch 254/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6693e-05 - val_loss: 7.4079e-05\n",
      "Epoch 255/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6949e-05 - val_loss: 7.4412e-05\n",
      "Epoch 256/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4623e-05 - val_loss: 7.5798e-05\n",
      "Epoch 257/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4912e-05 - val_loss: 7.3797e-05\n",
      "Epoch 258/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5474e-05 - val_loss: 8.2112e-05\n",
      "Epoch 259/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4878e-05 - val_loss: 7.4295e-05\n",
      "Epoch 260/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4429e-05 - val_loss: 7.4074e-05\n",
      "Epoch 261/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4927e-05 - val_loss: 7.3595e-05\n",
      "Epoch 262/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7220e-05 - val_loss: 7.3974e-05\n",
      "Epoch 263/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3605e-05 - val_loss: 8.6896e-05\n",
      "Epoch 264/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4045e-05 - val_loss: 7.5952e-05\n",
      "Epoch 265/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3071e-05 - val_loss: 7.4414e-05\n",
      "Epoch 266/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3620e-05 - val_loss: 7.3505e-05\n",
      "Epoch 267/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3518e-05 - val_loss: 7.4026e-05\n",
      "Epoch 268/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5193e-05 - val_loss: 7.4137e-05\n",
      "Epoch 269/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4479e-05 - val_loss: 7.7764e-05\n",
      "Epoch 270/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6870e-05 - val_loss: 7.3770e-05\n",
      "Epoch 271/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4505e-05 - val_loss: 7.4046e-05\n",
      "Epoch 272/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5429e-05 - val_loss: 7.9635e-05\n",
      "Epoch 273/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3073e-05 - val_loss: 7.6607e-05\n",
      "Epoch 274/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5837e-05 - val_loss: 7.9087e-05\n",
      "Epoch 275/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6536e-05 - val_loss: 7.5397e-05\n",
      "Epoch 276/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6944e-05 - val_loss: 7.3630e-05\n",
      "Epoch 277/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4830e-05 - val_loss: 7.6943e-05\n",
      "Epoch 278/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5644e-05 - val_loss: 7.9074e-05\n",
      "Epoch 279/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4681e-05 - val_loss: 7.3924e-05\n",
      "Epoch 280/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4622e-05 - val_loss: 7.9651e-05\n",
      "Epoch 281/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8086e-05 - val_loss: 7.6781e-05\n",
      "Epoch 282/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3089e-05 - val_loss: 7.3789e-05\n",
      "Epoch 283/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5283e-05 - val_loss: 7.9250e-05\n",
      "Epoch 284/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2377e-05 - val_loss: 7.3783e-05\n",
      "Epoch 285/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6319e-05 - val_loss: 9.1291e-05\n",
      "Epoch 286/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 7.6612e-05 - val_loss: 7.3790e-05\n",
      "Epoch 287/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7418e-05 - val_loss: 7.3722e-05\n",
      "Epoch 288/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6710e-05 - val_loss: 7.5125e-05\n",
      "Epoch 289/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8481e-05 - val_loss: 7.3316e-05\n",
      "Epoch 290/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3747e-05 - val_loss: 7.3282e-05\n",
      "Epoch 291/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2667e-05 - val_loss: 7.3430e-05\n",
      "Epoch 292/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3230e-05 - val_loss: 7.7182e-05\n",
      "Epoch 293/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4884e-05 - val_loss: 7.3599e-05\n",
      "Epoch 294/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6288e-05 - val_loss: 7.4863e-05\n",
      "Epoch 295/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4621e-05 - val_loss: 7.3766e-05\n",
      "Epoch 296/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4851e-05 - val_loss: 7.9015e-05\n",
      "Epoch 297/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4629e-05 - val_loss: 7.3619e-05\n",
      "Epoch 298/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5095e-05 - val_loss: 7.4983e-05\n",
      "Epoch 299/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 7.4051e-05 - val_loss: 7.3261e-05\n",
      "Epoch 300/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2839e-05 - val_loss: 7.6290e-05\n",
      "Epoch 301/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5609e-05 - val_loss: 7.3430e-05\n",
      "Epoch 302/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3631e-05 - val_loss: 7.3372e-05\n",
      "Epoch 303/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5737e-05 - val_loss: 7.3049e-05\n",
      "Epoch 304/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3357e-05 - val_loss: 7.7498e-05\n",
      "Epoch 305/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7562e-05 - val_loss: 7.7135e-05\n",
      "Epoch 306/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7058e-05 - val_loss: 7.3348e-05\n",
      "Epoch 307/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3279e-05 - val_loss: 7.6308e-05\n",
      "Epoch 308/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3413e-05 - val_loss: 7.3772e-05\n",
      "Epoch 309/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4572e-05 - val_loss: 7.4605e-05\n",
      "Epoch 310/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5843e-05 - val_loss: 7.3196e-05\n",
      "Epoch 311/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4885e-05 - val_loss: 7.4920e-05\n",
      "Epoch 312/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3642e-05 - val_loss: 7.5411e-05\n",
      "Epoch 313/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5189e-05 - val_loss: 7.8350e-05\n",
      "Epoch 314/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6730e-05 - val_loss: 7.6288e-05\n",
      "Epoch 315/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4608e-05 - val_loss: 7.4492e-05\n",
      "Epoch 316/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6277e-05 - val_loss: 7.6603e-05\n",
      "Epoch 317/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3797e-05 - val_loss: 7.6939e-05\n",
      "Epoch 318/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4629e-05 - val_loss: 7.3408e-05\n",
      "Epoch 319/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4143e-05 - val_loss: 7.4376e-05\n",
      "Epoch 320/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3530e-05 - val_loss: 7.4242e-05\n",
      "Epoch 321/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4027e-05 - val_loss: 7.3552e-05\n",
      "Epoch 322/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4512e-05 - val_loss: 7.7287e-05\n",
      "Epoch 323/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.8686e-05 - val_loss: 7.3382e-05\n",
      "Epoch 324/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3266e-05 - val_loss: 8.0266e-05\n",
      "Epoch 325/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7785e-05 - val_loss: 7.5901e-05\n",
      "Epoch 326/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4279e-05 - val_loss: 7.3463e-05\n",
      "Epoch 327/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2408e-05 - val_loss: 7.3776e-05\n",
      "Epoch 328/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6216e-05 - val_loss: 7.3216e-05\n",
      "Epoch 329/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6021e-05 - val_loss: 7.3007e-05\n",
      "Epoch 330/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3683e-05 - val_loss: 7.2926e-05\n",
      "Epoch 331/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5972e-05 - val_loss: 8.0913e-05\n",
      "Epoch 332/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3256e-05 - val_loss: 7.9881e-05\n",
      "Epoch 333/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1856e-05 - val_loss: 7.3887e-05\n",
      "Epoch 334/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2844e-05 - val_loss: 7.9051e-05\n",
      "Epoch 335/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5252e-05 - val_loss: 7.2841e-05\n",
      "Epoch 336/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5447e-05 - val_loss: 7.4429e-05\n",
      "Epoch 337/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2161e-05 - val_loss: 8.5986e-05\n",
      "Epoch 338/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7062e-05 - val_loss: 7.3899e-05\n",
      "Epoch 339/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3565e-05 - val_loss: 7.3793e-05\n",
      "Epoch 340/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3545e-05 - val_loss: 8.5581e-05\n",
      "Epoch 341/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4551e-05 - val_loss: 7.4854e-05\n",
      "Epoch 342/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4752e-05 - val_loss: 7.3367e-05\n",
      "Epoch 343/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4391e-05 - val_loss: 8.0063e-05\n",
      "Epoch 344/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4599e-05 - val_loss: 7.2671e-05\n",
      "Epoch 345/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3510e-05 - val_loss: 7.6726e-05\n",
      "Epoch 346/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2430e-05 - val_loss: 7.7160e-05\n",
      "Epoch 347/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4857e-05 - val_loss: 8.7279e-05\n",
      "Epoch 348/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4098e-05 - val_loss: 7.3056e-05\n",
      "Epoch 349/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5326e-05 - val_loss: 7.3998e-05\n",
      "Epoch 350/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3866e-05 - val_loss: 8.9632e-05\n",
      "Epoch 351/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5463e-05 - val_loss: 7.5144e-05\n",
      "Epoch 352/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0753e-05 - val_loss: 7.4795e-05\n",
      "Epoch 353/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3544e-05 - val_loss: 7.2662e-05\n",
      "Epoch 354/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2736e-05 - val_loss: 7.6289e-05\n",
      "Epoch 355/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2114e-05 - val_loss: 7.3254e-05\n",
      "Epoch 356/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3830e-05 - val_loss: 7.3515e-05\n",
      "Epoch 357/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3345e-05 - val_loss: 7.3368e-05\n",
      "Epoch 358/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4769e-05 - val_loss: 7.4814e-05\n",
      "Epoch 359/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1709e-05 - val_loss: 7.7739e-05\n",
      "Epoch 360/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3097e-05 - val_loss: 7.4130e-05\n",
      "Epoch 361/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4023e-05 - val_loss: 7.3980e-05\n",
      "Epoch 362/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5108e-05 - val_loss: 7.7298e-05\n",
      "Epoch 363/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2466e-05 - val_loss: 7.3238e-05\n",
      "Epoch 364/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1960e-05 - val_loss: 7.2763e-05\n",
      "Epoch 365/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2359e-05 - val_loss: 8.0944e-05\n",
      "Epoch 366/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1627e-05 - val_loss: 7.2810e-05\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1821e-05 - val_loss: 7.2595e-05\n",
      "Epoch 368/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2294e-05 - val_loss: 7.3936e-05\n",
      "Epoch 369/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3291e-05 - val_loss: 7.2661e-05\n",
      "Epoch 370/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1710e-05 - val_loss: 7.2489e-05\n",
      "Epoch 371/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1957e-05 - val_loss: 7.2234e-05\n",
      "Epoch 372/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4809e-05 - val_loss: 7.2284e-05\n",
      "Epoch 373/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3819e-05 - val_loss: 7.3992e-05\n",
      "Epoch 374/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2569e-05 - val_loss: 8.0521e-05\n",
      "Epoch 375/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5053e-05 - val_loss: 7.2576e-05\n",
      "Epoch 376/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5328e-05 - val_loss: 7.3564e-05\n",
      "Epoch 377/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2074e-05 - val_loss: 7.4816e-05\n",
      "Epoch 378/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3482e-05 - val_loss: 7.2600e-05\n",
      "Epoch 379/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2997e-05 - val_loss: 7.2768e-05\n",
      "Epoch 380/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1859e-05 - val_loss: 7.5180e-05\n",
      "Epoch 381/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5467e-05 - val_loss: 7.3057e-05\n",
      "Epoch 382/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3154e-05 - val_loss: 7.2900e-05\n",
      "Epoch 383/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3617e-05 - val_loss: 8.2875e-05\n",
      "Epoch 384/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3442e-05 - val_loss: 7.2835e-05\n",
      "Epoch 385/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2302e-05 - val_loss: 7.4750e-05\n",
      "Epoch 386/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2759e-05 - val_loss: 7.3095e-05\n",
      "Epoch 387/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1746e-05 - val_loss: 7.2670e-05\n",
      "Epoch 388/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.6617e-05 - val_loss: 7.3955e-05\n",
      "Epoch 389/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2321e-05 - val_loss: 7.5780e-05\n",
      "Epoch 390/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3592e-05 - val_loss: 7.5548e-05\n",
      "Epoch 391/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1610e-05 - val_loss: 8.0647e-05\n",
      "Epoch 392/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7912e-05 - val_loss: 7.1860e-05\n",
      "Epoch 393/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3201e-05 - val_loss: 7.3283e-05\n",
      "Epoch 394/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2027e-05 - val_loss: 7.6067e-05\n",
      "Epoch 395/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4579e-05 - val_loss: 7.2237e-05\n",
      "Epoch 396/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1593e-05 - val_loss: 8.2442e-05\n",
      "Epoch 397/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1974e-05 - val_loss: 7.4628e-05\n",
      "Epoch 398/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5288e-05 - val_loss: 7.3642e-05\n",
      "Epoch 399/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1302e-05 - val_loss: 7.1999e-05\n",
      "Epoch 400/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2187e-05 - val_loss: 7.2082e-05\n",
      "Epoch 401/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1221e-05 - val_loss: 7.1911e-05\n",
      "Epoch 402/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1830e-05 - val_loss: 7.1932e-05\n",
      "Epoch 403/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3543e-05 - val_loss: 8.9465e-05\n",
      "Epoch 404/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5766e-05 - val_loss: 7.3045e-05\n",
      "Epoch 405/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3589e-05 - val_loss: 7.2947e-05\n",
      "Epoch 406/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.7533e-05 - val_loss: 7.1711e-05\n",
      "Epoch 407/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0501e-05 - val_loss: 7.2665e-05\n",
      "Epoch 408/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1843e-05 - val_loss: 7.4302e-05\n",
      "Epoch 409/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4566e-05 - val_loss: 7.2844e-05\n",
      "Epoch 410/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5913e-05 - val_loss: 7.3223e-05\n",
      "Epoch 411/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4015e-05 - val_loss: 7.7607e-05\n",
      "Epoch 412/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1015e-05 - val_loss: 7.6650e-05\n",
      "Epoch 413/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5183e-05 - val_loss: 7.1904e-05\n",
      "Epoch 414/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3758e-05 - val_loss: 7.2731e-05\n",
      "Epoch 415/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1706e-05 - val_loss: 7.3378e-05\n",
      "Epoch 416/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0818e-05 - val_loss: 7.1802e-05\n",
      "Epoch 417/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2906e-05 - val_loss: 7.3130e-05\n",
      "Epoch 418/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3477e-05 - val_loss: 7.5952e-05\n",
      "Epoch 419/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3668e-05 - val_loss: 7.1598e-05\n",
      "Epoch 420/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0815e-05 - val_loss: 7.2754e-05\n",
      "Epoch 421/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1580e-05 - val_loss: 7.2007e-05\n",
      "Epoch 422/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1459e-05 - val_loss: 7.2570e-05\n",
      "Epoch 423/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2077e-05 - val_loss: 7.2311e-05\n",
      "Epoch 424/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2686e-05 - val_loss: 7.2953e-05\n",
      "Epoch 425/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4023e-05 - val_loss: 7.6276e-05\n",
      "Epoch 426/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0649e-05 - val_loss: 7.1516e-05\n",
      "Epoch 427/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1471e-05 - val_loss: 7.7344e-05\n",
      "Epoch 428/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2792e-05 - val_loss: 7.3596e-05\n",
      "Epoch 429/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0989e-05 - val_loss: 8.1646e-05\n",
      "Epoch 430/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2627e-05 - val_loss: 7.6238e-05\n",
      "Epoch 431/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4610e-05 - val_loss: 7.2939e-05\n",
      "Epoch 432/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1315e-05 - val_loss: 7.2820e-05\n",
      "Epoch 433/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2407e-05 - val_loss: 7.2639e-05\n",
      "Epoch 434/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2096e-05 - val_loss: 7.1728e-05\n",
      "Epoch 435/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2641e-05 - val_loss: 7.3503e-05\n",
      "Epoch 436/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5447e-05 - val_loss: 7.2089e-05\n",
      "Epoch 437/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0926e-05 - val_loss: 7.2323e-05\n",
      "Epoch 438/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1084e-05 - val_loss: 7.1513e-05\n",
      "Epoch 439/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1550e-05 - val_loss: 7.2064e-05\n",
      "Epoch 440/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1893e-05 - val_loss: 7.2369e-05\n",
      "Epoch 441/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1656e-05 - val_loss: 7.1979e-05\n",
      "Epoch 442/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2573e-05 - val_loss: 7.1486e-05\n",
      "Epoch 443/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3459e-05 - val_loss: 7.2293e-05\n",
      "Epoch 444/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2264e-05 - val_loss: 7.1537e-05\n",
      "Epoch 445/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0563e-05 - val_loss: 7.2953e-05\n",
      "Epoch 446/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1996e-05 - val_loss: 7.3374e-05\n",
      "Epoch 447/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4471e-05 - val_loss: 7.7301e-05\n",
      "Epoch 448/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1309e-05 - val_loss: 8.1892e-05\n",
      "Epoch 449/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0862e-05 - val_loss: 7.2407e-05\n",
      "Epoch 450/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.5494e-05 - val_loss: 7.1701e-05\n",
      "Epoch 451/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0340e-05 - val_loss: 7.2140e-05\n",
      "Epoch 452/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1508e-05 - val_loss: 7.1420e-05\n",
      "Epoch 453/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9742e-05 - val_loss: 7.5091e-05\n",
      "Epoch 454/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1747e-05 - val_loss: 7.1721e-05\n",
      "Epoch 455/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4866e-05 - val_loss: 7.7429e-05\n",
      "Epoch 456/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9911e-05 - val_loss: 7.9668e-05\n",
      "Epoch 457/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2291e-05 - val_loss: 7.1457e-05\n",
      "Epoch 458/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1448e-05 - val_loss: 7.1631e-05\n",
      "Epoch 459/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4952e-05 - val_loss: 7.3355e-05\n",
      "Epoch 460/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0108e-05 - val_loss: 7.6729e-05\n",
      "Epoch 461/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0077e-05 - val_loss: 7.1378e-05\n",
      "Epoch 462/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1268e-05 - val_loss: 7.3146e-05\n",
      "Epoch 463/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1230e-05 - val_loss: 7.3070e-05\n",
      "Epoch 464/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3178e-05 - val_loss: 7.3977e-05\n",
      "Epoch 465/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2101e-05 - val_loss: 7.4637e-05\n",
      "Epoch 466/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1716e-05 - val_loss: 7.4302e-05\n",
      "Epoch 467/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1780e-05 - val_loss: 7.3175e-05\n",
      "Epoch 468/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0379e-05 - val_loss: 7.5936e-05\n",
      "Epoch 469/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8926e-05 - val_loss: 7.2023e-05\n",
      "Epoch 470/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1884e-05 - val_loss: 7.2303e-05\n",
      "Epoch 471/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0112e-05 - val_loss: 7.8365e-05\n",
      "Epoch 472/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3185e-05 - val_loss: 7.4274e-05\n",
      "Epoch 473/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0896e-05 - val_loss: 7.1038e-05\n",
      "Epoch 474/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0208e-05 - val_loss: 7.1440e-05\n",
      "Epoch 475/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9704e-05 - val_loss: 7.2360e-05\n",
      "Epoch 476/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0757e-05 - val_loss: 7.1452e-05\n",
      "Epoch 477/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2591e-05 - val_loss: 7.1839e-05\n",
      "Epoch 478/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0872e-05 - val_loss: 7.3849e-05\n",
      "Epoch 479/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2126e-05 - val_loss: 7.1903e-05\n",
      "Epoch 480/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2472e-05 - val_loss: 7.2298e-05\n",
      "Epoch 481/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0447e-05 - val_loss: 7.0813e-05\n",
      "Epoch 482/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0070e-05 - val_loss: 7.2071e-05\n",
      "Epoch 483/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1835e-05 - val_loss: 7.1019e-05\n",
      "Epoch 484/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1422e-05 - val_loss: 7.0806e-05\n",
      "Epoch 485/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0091e-05 - val_loss: 7.0911e-05\n",
      "Epoch 486/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1546e-05 - val_loss: 7.7401e-05\n",
      "Epoch 487/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1846e-05 - val_loss: 7.1470e-05\n",
      "Epoch 488/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9875e-05 - val_loss: 7.6041e-05\n",
      "Epoch 489/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2546e-05 - val_loss: 7.6439e-05\n",
      "Epoch 490/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0113e-05 - val_loss: 7.3840e-05\n",
      "Epoch 491/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2792e-05 - val_loss: 7.3567e-05\n",
      "Epoch 492/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3431e-05 - val_loss: 7.1603e-05\n",
      "Epoch 493/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0886e-05 - val_loss: 7.1491e-05\n",
      "Epoch 494/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1200e-05 - val_loss: 7.0827e-05\n",
      "Epoch 495/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9110e-05 - val_loss: 7.1499e-05\n",
      "Epoch 496/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1229e-05 - val_loss: 7.1215e-05\n",
      "Epoch 497/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8606e-05 - val_loss: 7.0871e-05\n",
      "Epoch 498/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2619e-05 - val_loss: 7.1026e-05\n",
      "Epoch 499/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1839e-05 - val_loss: 7.1088e-05\n",
      "Epoch 500/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1034e-05 - val_loss: 7.1067e-05\n",
      "Epoch 501/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0690e-05 - val_loss: 7.8758e-05\n",
      "Epoch 502/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0214e-05 - val_loss: 7.1780e-05\n",
      "Epoch 503/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1261e-05 - val_loss: 7.0528e-05\n",
      "Epoch 504/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2638e-05 - val_loss: 7.3918e-05\n",
      "Epoch 505/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3622e-05 - val_loss: 7.0765e-05\n",
      "Epoch 506/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1138e-05 - val_loss: 7.0474e-05\n",
      "Epoch 507/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1270e-05 - val_loss: 7.0517e-05\n",
      "Epoch 508/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3279e-05 - val_loss: 7.6306e-05\n",
      "Epoch 509/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1312e-05 - val_loss: 7.1230e-05\n",
      "Epoch 510/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.4138e-05 - val_loss: 7.4502e-05\n",
      "Epoch 511/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1238e-05 - val_loss: 7.2655e-05\n",
      "Epoch 512/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1805e-05 - val_loss: 7.0871e-05\n",
      "Epoch 513/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0899e-05 - val_loss: 7.4053e-05\n",
      "Epoch 514/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9880e-05 - val_loss: 7.0788e-05\n",
      "Epoch 515/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1719e-05 - val_loss: 7.7697e-05\n",
      "Epoch 516/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2521e-05 - val_loss: 7.7303e-05\n",
      "Epoch 517/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2518e-05 - val_loss: 7.0691e-05\n",
      "Epoch 518/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1203e-05 - val_loss: 7.4002e-05\n",
      "Epoch 519/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0671e-05 - val_loss: 7.3476e-05\n",
      "Epoch 520/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1979e-05 - val_loss: 7.0763e-05\n",
      "Epoch 521/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3632e-05 - val_loss: 7.1806e-05\n",
      "Epoch 522/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0219e-05 - val_loss: 7.2565e-05\n",
      "Epoch 523/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1357e-05 - val_loss: 7.0696e-05\n",
      "Epoch 524/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1056e-05 - val_loss: 7.1868e-05\n",
      "Epoch 525/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9490e-05 - val_loss: 7.0895e-05\n",
      "Epoch 526/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0447e-05 - val_loss: 7.0872e-05\n",
      "Epoch 527/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1624e-05 - val_loss: 7.0449e-05\n",
      "Epoch 528/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8488e-05 - val_loss: 8.0591e-05\n",
      "Epoch 529/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2272e-05 - val_loss: 7.2962e-05\n",
      "Epoch 530/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0646e-05 - val_loss: 7.0178e-05\n",
      "Epoch 531/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0658e-05 - val_loss: 7.0570e-05\n",
      "Epoch 532/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0653e-05 - val_loss: 7.3775e-05\n",
      "Epoch 533/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9551e-05 - val_loss: 7.3068e-05\n",
      "Epoch 534/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.3930e-05 - val_loss: 7.7350e-05\n",
      "Epoch 535/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2094e-05 - val_loss: 7.2298e-05\n",
      "Epoch 536/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0167e-05 - val_loss: 7.4029e-05\n",
      "Epoch 537/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9139e-05 - val_loss: 7.0564e-05\n",
      "Epoch 538/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0165e-05 - val_loss: 7.0474e-05\n",
      "Epoch 539/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0441e-05 - val_loss: 7.0639e-05\n",
      "Epoch 540/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0487e-05 - val_loss: 7.0515e-05\n",
      "Epoch 541/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9427e-05 - val_loss: 7.0549e-05\n",
      "Epoch 542/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9901e-05 - val_loss: 7.0772e-05\n",
      "Epoch 543/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9825e-05 - val_loss: 7.5710e-05\n",
      "Epoch 544/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2321e-05 - val_loss: 7.2125e-05\n",
      "Epoch 545/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1023e-05 - val_loss: 6.9984e-05\n",
      "Epoch 546/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0814e-05 - val_loss: 6.9947e-05\n",
      "Epoch 547/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0205e-05 - val_loss: 7.2518e-05\n",
      "Epoch 548/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9851e-05 - val_loss: 7.0279e-05\n",
      "Epoch 549/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2710e-05 - val_loss: 7.1159e-05\n",
      "Epoch 550/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0402e-05 - val_loss: 7.1024e-05\n",
      "Epoch 551/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0868e-05 - val_loss: 7.2585e-05\n",
      "Epoch 552/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9717e-05 - val_loss: 7.0747e-05\n",
      "Epoch 553/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9521e-05 - val_loss: 6.9824e-05\n",
      "Epoch 554/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9707e-05 - val_loss: 7.0484e-05\n",
      "Epoch 555/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9260e-05 - val_loss: 7.7291e-05\n",
      "Epoch 556/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9900e-05 - val_loss: 6.9835e-05\n",
      "Epoch 557/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7189e-05 - val_loss: 6.9868e-05\n",
      "Epoch 558/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8761e-05 - val_loss: 7.0567e-05\n",
      "Epoch 559/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6814e-05 - val_loss: 7.6451e-05\n",
      "Epoch 560/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0328e-05 - val_loss: 7.0030e-05\n",
      "Epoch 561/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8510e-05 - val_loss: 7.0116e-05\n",
      "Epoch 562/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9094e-05 - val_loss: 6.9651e-05\n",
      "Epoch 563/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9700e-05 - val_loss: 7.0499e-05\n",
      "Epoch 564/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8389e-05 - val_loss: 7.5098e-05\n",
      "Epoch 565/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9763e-05 - val_loss: 7.1855e-05\n",
      "Epoch 566/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0381e-05 - val_loss: 7.1505e-05\n",
      "Epoch 567/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8097e-05 - val_loss: 6.9766e-05\n",
      "Epoch 568/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8689e-05 - val_loss: 6.9650e-05\n",
      "Epoch 569/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9534e-05 - val_loss: 6.9775e-05\n",
      "Epoch 570/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7740e-05 - val_loss: 6.9827e-05\n",
      "Epoch 571/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1443e-05 - val_loss: 7.0257e-05\n",
      "Epoch 572/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8683e-05 - val_loss: 6.9954e-05\n",
      "Epoch 573/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6253e-05 - val_loss: 7.1935e-05\n",
      "Epoch 574/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0224e-05 - val_loss: 7.0716e-05\n",
      "Epoch 575/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9157e-05 - val_loss: 7.3483e-05\n",
      "Epoch 576/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9870e-05 - val_loss: 6.9674e-05\n",
      "Epoch 577/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9341e-05 - val_loss: 7.8873e-05\n",
      "Epoch 578/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2125e-05 - val_loss: 7.0810e-05\n",
      "Epoch 579/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0880e-05 - val_loss: 7.0601e-05\n",
      "Epoch 580/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9090e-05 - val_loss: 6.9789e-05\n",
      "Epoch 581/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8818e-05 - val_loss: 7.1132e-05\n",
      "Epoch 582/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0042e-05 - val_loss: 7.0670e-05\n",
      "Epoch 583/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9731e-05 - val_loss: 7.9275e-05\n",
      "Epoch 584/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0588e-05 - val_loss: 7.5640e-05\n",
      "Epoch 585/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1701e-05 - val_loss: 7.0576e-05\n",
      "Epoch 586/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0689e-05 - val_loss: 6.9515e-05\n",
      "Epoch 587/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7276e-05 - val_loss: 6.9612e-05\n",
      "Epoch 588/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8652e-05 - val_loss: 6.9641e-05\n",
      "Epoch 589/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9790e-05 - val_loss: 7.0904e-05\n",
      "Epoch 590/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0495e-05 - val_loss: 7.0219e-05\n",
      "Epoch 591/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9332e-05 - val_loss: 7.0733e-05\n",
      "Epoch 592/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8894e-05 - val_loss: 7.1346e-05\n",
      "Epoch 593/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8876e-05 - val_loss: 7.0106e-05\n",
      "Epoch 594/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8321e-05 - val_loss: 7.3690e-05\n",
      "Epoch 595/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8442e-05 - val_loss: 6.9804e-05\n",
      "Epoch 596/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7066e-05 - val_loss: 6.9811e-05\n",
      "Epoch 597/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8702e-05 - val_loss: 6.9366e-05\n",
      "Epoch 598/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0567e-05 - val_loss: 6.9496e-05\n",
      "Epoch 599/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1054e-05 - val_loss: 6.9896e-05\n",
      "Epoch 600/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7967e-05 - val_loss: 6.9350e-05\n",
      "Epoch 601/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9332e-05 - val_loss: 6.9264e-05\n",
      "Epoch 602/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8476e-05 - val_loss: 6.9659e-05\n",
      "Epoch 603/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8960e-05 - val_loss: 6.9698e-05\n",
      "Epoch 604/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9564e-05 - val_loss: 6.9586e-05\n",
      "Epoch 605/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9405e-05 - val_loss: 7.0027e-05\n",
      "Epoch 606/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7148e-05 - val_loss: 6.9528e-05\n",
      "Epoch 607/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9525e-05 - val_loss: 7.3249e-05\n",
      "Epoch 608/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1309e-05 - val_loss: 6.9992e-05\n",
      "Epoch 609/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8106e-05 - val_loss: 7.0020e-05\n",
      "Epoch 610/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0099e-05 - val_loss: 7.5521e-05\n",
      "Epoch 611/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8066e-05 - val_loss: 7.9510e-05\n",
      "Epoch 612/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9558e-05 - val_loss: 7.1519e-05\n",
      "Epoch 613/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9780e-05 - val_loss: 6.9533e-05\n",
      "Epoch 614/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8542e-05 - val_loss: 7.2261e-05\n",
      "Epoch 615/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0125e-05 - val_loss: 6.9801e-05\n",
      "Epoch 616/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7998e-05 - val_loss: 7.0028e-05\n",
      "Epoch 617/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9890e-05 - val_loss: 7.1940e-05\n",
      "Epoch 618/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9375e-05 - val_loss: 6.9288e-05\n",
      "Epoch 619/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9437e-05 - val_loss: 7.0274e-05\n",
      "Epoch 620/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8011e-05 - val_loss: 6.9126e-05\n",
      "Epoch 621/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8889e-05 - val_loss: 7.4608e-05\n",
      "Epoch 622/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8292e-05 - val_loss: 7.0039e-05\n",
      "Epoch 623/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8893e-05 - val_loss: 6.9957e-05\n",
      "Epoch 624/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8088e-05 - val_loss: 7.1789e-05\n",
      "Epoch 625/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0390e-05 - val_loss: 6.9516e-05\n",
      "Epoch 626/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0006e-05 - val_loss: 7.2528e-05\n",
      "Epoch 627/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0662e-05 - val_loss: 6.9689e-05\n",
      "Epoch 628/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7239e-05 - val_loss: 6.9576e-05\n",
      "Epoch 629/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9910e-05 - val_loss: 6.9314e-05\n",
      "Epoch 630/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9051e-05 - val_loss: 6.9635e-05\n",
      "Epoch 631/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2333e-05 - val_loss: 6.9099e-05\n",
      "Epoch 632/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9898e-05 - val_loss: 7.0131e-05\n",
      "Epoch 633/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7359e-05 - val_loss: 6.9134e-05\n",
      "Epoch 634/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9045e-05 - val_loss: 7.0895e-05\n",
      "Epoch 635/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8712e-05 - val_loss: 6.9631e-05\n",
      "Epoch 636/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2503e-05 - val_loss: 6.9462e-05\n",
      "Epoch 637/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0178e-05 - val_loss: 6.9731e-05\n",
      "Epoch 638/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8677e-05 - val_loss: 6.9092e-05\n",
      "Epoch 639/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8400e-05 - val_loss: 7.0234e-05\n",
      "Epoch 640/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7830e-05 - val_loss: 6.9648e-05\n",
      "Epoch 641/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8349e-05 - val_loss: 7.1863e-05\n",
      "Epoch 642/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8652e-05 - val_loss: 7.2567e-05\n",
      "Epoch 643/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9387e-05 - val_loss: 6.9944e-05\n",
      "Epoch 644/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8720e-05 - val_loss: 7.0026e-05\n",
      "Epoch 645/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9227e-05 - val_loss: 6.9535e-05\n",
      "Epoch 646/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7438e-05 - val_loss: 7.0060e-05\n",
      "Epoch 647/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7670e-05 - val_loss: 6.9142e-05\n",
      "Epoch 648/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1135e-05 - val_loss: 6.9323e-05\n",
      "Epoch 649/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9125e-05 - val_loss: 6.9135e-05\n",
      "Epoch 650/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7526e-05 - val_loss: 7.1192e-05\n",
      "Epoch 651/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8722e-05 - val_loss: 7.1005e-05\n",
      "Epoch 652/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9727e-05 - val_loss: 6.9255e-05\n",
      "Epoch 653/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9047e-05 - val_loss: 6.9185e-05\n",
      "Epoch 654/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1845e-05 - val_loss: 6.9468e-05\n",
      "Epoch 655/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7694e-05 - val_loss: 6.9220e-05\n",
      "Epoch 656/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0041e-05 - val_loss: 6.9075e-05\n",
      "Epoch 657/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8601e-05 - val_loss: 6.9011e-05\n",
      "Epoch 658/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9695e-05 - val_loss: 6.9758e-05\n",
      "Epoch 659/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0289e-05 - val_loss: 6.9087e-05\n",
      "Epoch 660/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7929e-05 - val_loss: 6.9076e-05\n",
      "Epoch 661/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9269e-05 - val_loss: 6.9197e-05\n",
      "Epoch 662/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8611e-05 - val_loss: 7.8733e-05\n",
      "Epoch 663/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8943e-05 - val_loss: 7.0026e-05\n",
      "Epoch 664/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0306e-05 - val_loss: 6.9191e-05\n",
      "Epoch 665/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7324e-05 - val_loss: 7.3603e-05\n",
      "Epoch 666/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7807e-05 - val_loss: 6.9658e-05\n",
      "Epoch 667/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6186e-05 - val_loss: 6.9569e-05\n",
      "Epoch 668/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6841e-05 - val_loss: 6.9447e-05\n",
      "Epoch 669/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9601e-05 - val_loss: 6.9729e-05\n",
      "Epoch 670/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7094e-05 - val_loss: 6.9433e-05\n",
      "Epoch 671/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0884e-05 - val_loss: 6.9081e-05\n",
      "Epoch 672/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7215e-05 - val_loss: 6.9072e-05\n",
      "Epoch 673/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5528e-05 - val_loss: 7.9425e-05\n",
      "Epoch 674/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8746e-05 - val_loss: 7.0106e-05\n",
      "Epoch 675/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1455e-05 - val_loss: 6.9687e-05\n",
      "Epoch 676/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9337e-05 - val_loss: 6.9805e-05\n",
      "Epoch 677/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8884e-05 - val_loss: 6.9535e-05\n",
      "Epoch 678/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1518e-05 - val_loss: 6.9654e-05\n",
      "Epoch 679/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8071e-05 - val_loss: 6.9974e-05\n",
      "Epoch 680/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6581e-05 - val_loss: 6.9400e-05\n",
      "Epoch 681/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7981e-05 - val_loss: 6.9271e-05\n",
      "Epoch 682/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6871e-05 - val_loss: 7.3177e-05\n",
      "Epoch 683/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2417e-05 - val_loss: 6.9015e-05\n",
      "Epoch 684/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8459e-05 - val_loss: 7.2003e-05\n",
      "Epoch 685/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8435e-05 - val_loss: 6.8955e-05\n",
      "Epoch 686/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5239e-05 - val_loss: 7.0495e-05\n",
      "Epoch 687/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7733e-05 - val_loss: 6.9276e-05\n",
      "Epoch 688/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8172e-05 - val_loss: 6.9269e-05\n",
      "Epoch 689/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7608e-05 - val_loss: 7.2077e-05\n",
      "Epoch 690/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.2032e-05 - val_loss: 6.9636e-05\n",
      "Epoch 691/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8733e-05 - val_loss: 7.1465e-05\n",
      "Epoch 692/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9096e-05 - val_loss: 6.9453e-05\n",
      "Epoch 693/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0019e-05 - val_loss: 6.9602e-05\n",
      "Epoch 694/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7907e-05 - val_loss: 6.9491e-05\n",
      "Epoch 695/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7401e-05 - val_loss: 7.0300e-05\n",
      "Epoch 696/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9883e-05 - val_loss: 6.9696e-05\n",
      "Epoch 697/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6718e-05 - val_loss: 7.1619e-05\n",
      "Epoch 698/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7966e-05 - val_loss: 6.9125e-05\n",
      "Epoch 699/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9124e-05 - val_loss: 6.8945e-05\n",
      "Epoch 700/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6761e-05 - val_loss: 7.0021e-05\n",
      "Epoch 701/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9404e-05 - val_loss: 7.2933e-05\n",
      "Epoch 702/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7161e-05 - val_loss: 6.8936e-05\n",
      "Epoch 703/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9833e-05 - val_loss: 6.9387e-05\n",
      "Epoch 704/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7964e-05 - val_loss: 6.9119e-05\n",
      "Epoch 705/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8750e-05 - val_loss: 7.0627e-05\n",
      "Epoch 706/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9718e-05 - val_loss: 6.9938e-05\n",
      "Epoch 707/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7865e-05 - val_loss: 7.1437e-05\n",
      "Epoch 708/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8881e-05 - val_loss: 6.9458e-05\n",
      "Epoch 709/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8923e-05 - val_loss: 6.9182e-05\n",
      "Epoch 710/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9343e-05 - val_loss: 6.9573e-05\n",
      "Epoch 711/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8790e-05 - val_loss: 6.9003e-05\n",
      "Epoch 712/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7941e-05 - val_loss: 6.9942e-05\n",
      "Epoch 713/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8816e-05 - val_loss: 6.9283e-05\n",
      "Epoch 714/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7868e-05 - val_loss: 7.0144e-05\n",
      "Epoch 715/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6480e-05 - val_loss: 6.9205e-05\n",
      "Epoch 716/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9114e-05 - val_loss: 6.9283e-05\n",
      "Epoch 717/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7604e-05 - val_loss: 7.0678e-05\n",
      "Epoch 718/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7651e-05 - val_loss: 6.9220e-05\n",
      "Epoch 719/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0362e-05 - val_loss: 6.9037e-05\n",
      "Epoch 720/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8428e-05 - val_loss: 7.2797e-05\n",
      "Epoch 721/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8734e-05 - val_loss: 7.0850e-05\n",
      "Epoch 722/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0180e-05 - val_loss: 6.9320e-05\n",
      "Epoch 723/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7179e-05 - val_loss: 6.9936e-05\n",
      "Epoch 724/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8584e-05 - val_loss: 6.9304e-05\n",
      "Epoch 725/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8107e-05 - val_loss: 6.9139e-05\n",
      "Epoch 726/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6507e-05 - val_loss: 6.9472e-05\n",
      "Epoch 727/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8525e-05 - val_loss: 6.9135e-05\n",
      "Epoch 728/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7479e-05 - val_loss: 6.9041e-05\n",
      "Epoch 729/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8469e-05 - val_loss: 6.9463e-05\n",
      "Epoch 730/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8618e-05 - val_loss: 6.9043e-05\n",
      "Epoch 731/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9206e-05 - val_loss: 6.8828e-05\n",
      "Epoch 732/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9856e-05 - val_loss: 7.1890e-05\n",
      "Epoch 733/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8386e-05 - val_loss: 6.8901e-05\n",
      "Epoch 734/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8056e-05 - val_loss: 7.1430e-05\n",
      "Epoch 735/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9629e-05 - val_loss: 6.9207e-05\n",
      "Epoch 736/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7560e-05 - val_loss: 6.8892e-05\n",
      "Epoch 737/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8459e-05 - val_loss: 7.0189e-05\n",
      "Epoch 738/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9155e-05 - val_loss: 6.9007e-05\n",
      "Epoch 739/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8617e-05 - val_loss: 6.9262e-05\n",
      "Epoch 740/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9780e-05 - val_loss: 7.0235e-05\n",
      "Epoch 741/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6394e-05 - val_loss: 6.9154e-05\n",
      "Epoch 742/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0664e-05 - val_loss: 7.0481e-05\n",
      "Epoch 743/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8822e-05 - val_loss: 7.2037e-05\n",
      "Epoch 744/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8006e-05 - val_loss: 7.2042e-05\n",
      "Epoch 745/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8476e-05 - val_loss: 7.2694e-05\n",
      "Epoch 746/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8166e-05 - val_loss: 6.9220e-05\n",
      "Epoch 747/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7797e-05 - val_loss: 6.9612e-05\n",
      "Epoch 748/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8063e-05 - val_loss: 7.2202e-05\n",
      "Epoch 749/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8598e-05 - val_loss: 6.8899e-05\n",
      "Epoch 750/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.7075e-05 - val_loss: 7.0913e-05\n",
      "Epoch 751/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.8882e-05 - val_loss: 6.9327e-05\n",
      "Epoch 752/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.5588e-05 - val_loss: 6.9121e-05\n",
      "Epoch 753/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.7408e-05 - val_loss: 6.9005e-05\n",
      "Epoch 754/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7158e-05 - val_loss: 6.9187e-05\n",
      "Epoch 755/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6620e-05 - val_loss: 6.8781e-05\n",
      "Epoch 756/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9646e-05 - val_loss: 6.9745e-05\n",
      "Epoch 757/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8874e-05 - val_loss: 6.9615e-05\n",
      "Epoch 758/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8100e-05 - val_loss: 6.9279e-05\n",
      "Epoch 759/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7074e-05 - val_loss: 6.9542e-05\n",
      "Epoch 760/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7737e-05 - val_loss: 6.9188e-05\n",
      "Epoch 761/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8336e-05 - val_loss: 7.0204e-05\n",
      "Epoch 762/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8372e-05 - val_loss: 6.9610e-05\n",
      "Epoch 763/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7705e-05 - val_loss: 6.9354e-05\n",
      "Epoch 764/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6105e-05 - val_loss: 6.9176e-05\n",
      "Epoch 765/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7469e-05 - val_loss: 7.0008e-05\n",
      "Epoch 766/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9734e-05 - val_loss: 7.6446e-05\n",
      "Epoch 767/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7802e-05 - val_loss: 6.8861e-05\n",
      "Epoch 768/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9081e-05 - val_loss: 6.9487e-05\n",
      "Epoch 769/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9661e-05 - val_loss: 6.9235e-05\n",
      "Epoch 770/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7055e-05 - val_loss: 7.4274e-05\n",
      "Epoch 771/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8679e-05 - val_loss: 6.9110e-05\n",
      "Epoch 772/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9921e-05 - val_loss: 6.8838e-05\n",
      "Epoch 773/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6933e-05 - val_loss: 6.9128e-05\n",
      "Epoch 774/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8358e-05 - val_loss: 6.9657e-05\n",
      "Epoch 775/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8169e-05 - val_loss: 6.8695e-05\n",
      "Epoch 776/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8872e-05 - val_loss: 6.9014e-05\n",
      "Epoch 777/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8322e-05 - val_loss: 7.0600e-05\n",
      "Epoch 778/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7935e-05 - val_loss: 6.8844e-05\n",
      "Epoch 779/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7858e-05 - val_loss: 7.0702e-05\n",
      "Epoch 780/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1158e-05 - val_loss: 6.9197e-05\n",
      "Epoch 781/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6767e-05 - val_loss: 7.0484e-05\n",
      "Epoch 782/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0389e-05 - val_loss: 6.9113e-05\n",
      "Epoch 783/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8983e-05 - val_loss: 6.8719e-05\n",
      "Epoch 784/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6367e-05 - val_loss: 6.8751e-05\n",
      "Epoch 785/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6297e-05 - val_loss: 6.8925e-05\n",
      "Epoch 786/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7077e-05 - val_loss: 6.8882e-05\n",
      "Epoch 787/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7119e-05 - val_loss: 6.9035e-05\n",
      "Epoch 788/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8269e-05 - val_loss: 7.0411e-05\n",
      "Epoch 789/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9116e-05 - val_loss: 6.9621e-05\n",
      "Epoch 790/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8389e-05 - val_loss: 7.0011e-05\n",
      "Epoch 791/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8102e-05 - val_loss: 6.8758e-05\n",
      "Epoch 792/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7059e-05 - val_loss: 6.9020e-05\n",
      "Epoch 793/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8818e-05 - val_loss: 6.9751e-05\n",
      "Epoch 794/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8866e-05 - val_loss: 6.9842e-05\n",
      "Epoch 795/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8037e-05 - val_loss: 6.9052e-05\n",
      "Epoch 796/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0833e-05 - val_loss: 6.8853e-05\n",
      "Epoch 797/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7838e-05 - val_loss: 6.9362e-05\n",
      "Epoch 798/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8205e-05 - val_loss: 6.8655e-05\n",
      "Epoch 799/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9855e-05 - val_loss: 6.8792e-05\n",
      "Epoch 800/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8403e-05 - val_loss: 6.9946e-05\n",
      "Epoch 801/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7869e-05 - val_loss: 6.8635e-05\n",
      "Epoch 802/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5891e-05 - val_loss: 6.8959e-05\n",
      "Epoch 803/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8364e-05 - val_loss: 6.8931e-05\n",
      "Epoch 804/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5257e-05 - val_loss: 6.8874e-05\n",
      "Epoch 805/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5501e-05 - val_loss: 6.8640e-05\n",
      "Epoch 806/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6889e-05 - val_loss: 6.9299e-05\n",
      "Epoch 807/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0479e-05 - val_loss: 6.9473e-05\n",
      "Epoch 808/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.8479e-05 - val_loss: 6.9106e-05\n",
      "Epoch 809/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9044e-05 - val_loss: 6.9029e-05\n",
      "Epoch 810/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7731e-05 - val_loss: 6.8825e-05\n",
      "Epoch 811/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0419e-05 - val_loss: 6.9084e-05\n",
      "Epoch 812/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5948e-05 - val_loss: 6.9395e-05\n",
      "Epoch 813/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8187e-05 - val_loss: 6.9790e-05\n",
      "Epoch 814/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8659e-05 - val_loss: 6.9696e-05\n",
      "Epoch 815/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8494e-05 - val_loss: 6.8903e-05\n",
      "Epoch 816/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8320e-05 - val_loss: 7.1163e-05\n",
      "Epoch 817/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9712e-05 - val_loss: 6.9407e-05\n",
      "Epoch 818/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6380e-05 - val_loss: 7.0393e-05\n",
      "Epoch 819/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5453e-05 - val_loss: 6.9123e-05\n",
      "Epoch 820/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5978e-05 - val_loss: 6.9549e-05\n",
      "Epoch 821/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7390e-05 - val_loss: 7.1605e-05\n",
      "Epoch 822/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5078e-05 - val_loss: 6.8810e-05\n",
      "Epoch 823/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7805e-05 - val_loss: 6.9869e-05\n",
      "Epoch 824/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9642e-05 - val_loss: 6.8713e-05\n",
      "Epoch 825/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5261e-05 - val_loss: 6.8678e-05\n",
      "Epoch 826/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7087e-05 - val_loss: 6.8656e-05\n",
      "Epoch 827/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7020e-05 - val_loss: 6.8838e-05\n",
      "Epoch 828/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1829e-05 - val_loss: 6.8795e-05\n",
      "Epoch 829/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8331e-05 - val_loss: 6.8938e-05\n",
      "Epoch 830/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.8998e-05 - val_loss: 6.9454e-05\n",
      "Epoch 831/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.9291e-05 - val_loss: 6.9240e-05\n",
      "Epoch 832/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.8286e-05 - val_loss: 6.9980e-05\n",
      "Epoch 833/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6788e-05 - val_loss: 6.9687e-05\n",
      "Epoch 834/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6862e-05 - val_loss: 6.8951e-05\n",
      "Epoch 835/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7874e-05 - val_loss: 6.8693e-05\n",
      "Epoch 836/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8674e-05 - val_loss: 6.9401e-05\n",
      "Epoch 837/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.8274e-05 - val_loss: 6.8979e-05\n",
      "Epoch 838/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6309e-05 - val_loss: 7.0628e-05\n",
      "Epoch 839/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7508e-05 - val_loss: 6.9161e-05\n",
      "Epoch 840/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8401e-05 - val_loss: 6.8566e-05\n",
      "Epoch 841/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6880e-05 - val_loss: 7.2102e-05\n",
      "Epoch 842/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0270e-05 - val_loss: 6.9087e-05\n",
      "Epoch 843/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6195e-05 - val_loss: 6.8609e-05\n",
      "Epoch 844/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7888e-05 - val_loss: 7.1360e-05\n",
      "Epoch 845/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7803e-05 - val_loss: 7.0757e-05\n",
      "Epoch 846/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6285e-05 - val_loss: 6.8947e-05\n",
      "Epoch 847/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7230e-05 - val_loss: 6.9065e-05\n",
      "Epoch 848/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6556e-05 - val_loss: 6.8699e-05\n",
      "Epoch 849/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6378e-05 - val_loss: 6.8831e-05\n",
      "Epoch 850/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7159e-05 - val_loss: 6.9039e-05\n",
      "Epoch 851/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6587e-05 - val_loss: 6.8670e-05\n",
      "Epoch 852/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8136e-05 - val_loss: 7.1255e-05\n",
      "Epoch 853/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7900e-05 - val_loss: 7.0964e-05\n",
      "Epoch 854/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8075e-05 - val_loss: 6.9439e-05\n",
      "Epoch 855/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9630e-05 - val_loss: 6.9415e-05\n",
      "Epoch 856/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7920e-05 - val_loss: 6.8674e-05\n",
      "Epoch 857/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6896e-05 - val_loss: 6.8696e-05\n",
      "Epoch 858/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9002e-05 - val_loss: 6.8661e-05\n",
      "Epoch 859/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7741e-05 - val_loss: 6.9480e-05\n",
      "Epoch 860/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9884e-05 - val_loss: 6.8843e-05\n",
      "Epoch 861/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8671e-05 - val_loss: 6.8613e-05\n",
      "Epoch 862/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8134e-05 - val_loss: 6.9217e-05\n",
      "Epoch 863/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7710e-05 - val_loss: 6.9374e-05\n",
      "Epoch 864/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5951e-05 - val_loss: 6.9060e-05\n",
      "Epoch 865/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9094e-05 - val_loss: 6.9048e-05\n",
      "Epoch 866/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7946e-05 - val_loss: 6.9036e-05\n",
      "Epoch 867/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.6214e-05 - val_loss: 6.8495e-05\n",
      "Epoch 868/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.5205e-05 - val_loss: 6.9037e-05\n",
      "Epoch 869/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.9238e-05 - val_loss: 6.8465e-05\n",
      "Epoch 870/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.8744e-05 - val_loss: 6.8913e-05\n",
      "Epoch 871/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.6931e-05 - val_loss: 7.0247e-05\n",
      "Epoch 872/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.6245e-05 - val_loss: 6.9075e-05\n",
      "Epoch 873/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6121e-05 - val_loss: 6.9314e-05\n",
      "Epoch 874/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.8081e-05 - val_loss: 6.8518e-05\n",
      "Epoch 875/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.6537e-05 - val_loss: 6.9285e-05\n",
      "Epoch 876/1000\n",
      "590/590 [==============================] - 1s 2ms/step - loss: 6.7202e-05 - val_loss: 6.8736e-05\n",
      "Epoch 877/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7477e-05 - val_loss: 6.8833e-05\n",
      "Epoch 878/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9340e-05 - val_loss: 6.8653e-05\n",
      "Epoch 879/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7140e-05 - val_loss: 7.0958e-05\n",
      "Epoch 880/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8824e-05 - val_loss: 7.1373e-05\n",
      "Epoch 881/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7464e-05 - val_loss: 6.9291e-05\n",
      "Epoch 882/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7391e-05 - val_loss: 6.9670e-05\n",
      "Epoch 883/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7856e-05 - val_loss: 6.8561e-05\n",
      "Epoch 884/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8367e-05 - val_loss: 7.3627e-05\n",
      "Epoch 885/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7126e-05 - val_loss: 6.9422e-05\n",
      "Epoch 886/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7094e-05 - val_loss: 6.9106e-05\n",
      "Epoch 887/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9374e-05 - val_loss: 6.9038e-05\n",
      "Epoch 888/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8636e-05 - val_loss: 6.8577e-05\n",
      "Epoch 889/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6586e-05 - val_loss: 6.9982e-05\n",
      "Epoch 890/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7213e-05 - val_loss: 6.8526e-05\n",
      "Epoch 891/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7822e-05 - val_loss: 6.9009e-05\n",
      "Epoch 892/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7045e-05 - val_loss: 6.8811e-05\n",
      "Epoch 893/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7898e-05 - val_loss: 6.8797e-05\n",
      "Epoch 894/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8087e-05 - val_loss: 7.2038e-05\n",
      "Epoch 895/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8272e-05 - val_loss: 6.8454e-05\n",
      "Epoch 896/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7657e-05 - val_loss: 6.9522e-05\n",
      "Epoch 897/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8150e-05 - val_loss: 6.9379e-05\n",
      "Epoch 898/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8054e-05 - val_loss: 6.8972e-05\n",
      "Epoch 899/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.4723e-05 - val_loss: 6.8542e-05\n",
      "Epoch 900/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6434e-05 - val_loss: 6.8428e-05\n",
      "Epoch 901/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8743e-05 - val_loss: 6.9152e-05\n",
      "Epoch 902/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6118e-05 - val_loss: 6.8866e-05\n",
      "Epoch 903/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6712e-05 - val_loss: 7.0269e-05\n",
      "Epoch 904/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7720e-05 - val_loss: 6.8633e-05\n",
      "Epoch 905/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8879e-05 - val_loss: 6.9926e-05\n",
      "Epoch 906/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1269e-05 - val_loss: 6.8583e-05\n",
      "Epoch 907/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5678e-05 - val_loss: 6.8549e-05\n",
      "Epoch 908/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7803e-05 - val_loss: 6.9041e-05\n",
      "Epoch 909/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8135e-05 - val_loss: 6.9561e-05\n",
      "Epoch 910/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6751e-05 - val_loss: 6.8792e-05\n",
      "Epoch 911/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7763e-05 - val_loss: 6.9802e-05\n",
      "Epoch 912/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8279e-05 - val_loss: 6.8785e-05\n",
      "Epoch 913/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8201e-05 - val_loss: 6.9433e-05\n",
      "Epoch 914/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8111e-05 - val_loss: 6.8840e-05\n",
      "Epoch 915/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6231e-05 - val_loss: 6.8598e-05\n",
      "Epoch 916/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7799e-05 - val_loss: 6.8519e-05\n",
      "Epoch 917/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8177e-05 - val_loss: 7.3387e-05\n",
      "Epoch 918/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8207e-05 - val_loss: 6.8648e-05\n",
      "Epoch 919/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6072e-05 - val_loss: 6.8720e-05\n",
      "Epoch 920/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7325e-05 - val_loss: 6.8563e-05\n",
      "Epoch 921/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7299e-05 - val_loss: 6.9731e-05\n",
      "Epoch 922/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8728e-05 - val_loss: 6.9532e-05\n",
      "Epoch 923/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7858e-05 - val_loss: 6.8559e-05\n",
      "Epoch 924/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7614e-05 - val_loss: 6.8651e-05\n",
      "Epoch 925/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5437e-05 - val_loss: 6.9309e-05\n",
      "Epoch 926/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6143e-05 - val_loss: 6.8617e-05\n",
      "Epoch 927/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7661e-05 - val_loss: 6.8710e-05\n",
      "Epoch 928/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6161e-05 - val_loss: 6.9148e-05\n",
      "Epoch 929/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8283e-05 - val_loss: 6.9117e-05\n",
      "Epoch 930/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8804e-05 - val_loss: 6.9779e-05\n",
      "Epoch 931/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8832e-05 - val_loss: 7.0370e-05\n",
      "Epoch 932/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7293e-05 - val_loss: 6.8560e-05\n",
      "Epoch 933/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7151e-05 - val_loss: 6.9716e-05\n",
      "Epoch 934/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6385e-05 - val_loss: 6.9343e-05\n",
      "Epoch 935/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7614e-05 - val_loss: 6.8689e-05\n",
      "Epoch 936/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6165e-05 - val_loss: 7.0031e-05\n",
      "Epoch 937/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9503e-05 - val_loss: 6.8748e-05\n",
      "Epoch 938/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9405e-05 - val_loss: 6.9208e-05\n",
      "Epoch 939/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8147e-05 - val_loss: 6.8568e-05\n",
      "Epoch 940/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6853e-05 - val_loss: 6.8622e-05\n",
      "Epoch 941/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8031e-05 - val_loss: 6.8487e-05\n",
      "Epoch 942/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6625e-05 - val_loss: 6.8709e-05\n",
      "Epoch 943/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6941e-05 - val_loss: 6.8540e-05\n",
      "Epoch 944/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8200e-05 - val_loss: 6.8426e-05\n",
      "Epoch 945/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7718e-05 - val_loss: 6.8530e-05\n",
      "Epoch 946/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6636e-05 - val_loss: 6.8805e-05\n",
      "Epoch 947/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9400e-05 - val_loss: 6.9415e-05\n",
      "Epoch 948/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9842e-05 - val_loss: 6.8636e-05\n",
      "Epoch 949/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8755e-05 - val_loss: 6.8965e-05\n",
      "Epoch 950/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6161e-05 - val_loss: 6.8844e-05\n",
      "Epoch 951/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5874e-05 - val_loss: 6.9911e-05\n",
      "Epoch 952/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8304e-05 - val_loss: 6.8581e-05\n",
      "Epoch 953/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7588e-05 - val_loss: 6.8463e-05\n",
      "Epoch 954/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7126e-05 - val_loss: 6.9586e-05\n",
      "Epoch 955/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9454e-05 - val_loss: 6.8594e-05\n",
      "Epoch 956/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7131e-05 - val_loss: 6.8824e-05\n",
      "Epoch 957/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6945e-05 - val_loss: 6.8574e-05\n",
      "Epoch 958/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6780e-05 - val_loss: 7.1009e-05\n",
      "Epoch 959/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8612e-05 - val_loss: 6.8552e-05\n",
      "Epoch 960/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7372e-05 - val_loss: 6.9144e-05\n",
      "Epoch 961/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6815e-05 - val_loss: 6.8571e-05\n",
      "Epoch 962/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6931e-05 - val_loss: 6.9581e-05\n",
      "Epoch 963/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6725e-05 - val_loss: 7.0537e-05\n",
      "Epoch 964/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6860e-05 - val_loss: 6.8618e-05\n",
      "Epoch 965/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0171e-05 - val_loss: 6.9210e-05\n",
      "Epoch 966/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5008e-05 - val_loss: 7.0858e-05\n",
      "Epoch 967/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8657e-05 - val_loss: 6.8454e-05\n",
      "Epoch 968/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8130e-05 - val_loss: 6.8988e-05\n",
      "Epoch 969/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8838e-05 - val_loss: 6.8696e-05\n",
      "Epoch 970/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6649e-05 - val_loss: 6.8832e-05\n",
      "Epoch 971/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7620e-05 - val_loss: 6.8383e-05\n",
      "Epoch 972/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5857e-05 - val_loss: 6.9070e-05\n",
      "Epoch 973/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6821e-05 - val_loss: 6.8756e-05\n",
      "Epoch 974/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6242e-05 - val_loss: 6.8528e-05\n",
      "Epoch 975/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.1667e-05 - val_loss: 6.9232e-05\n",
      "Epoch 976/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6545e-05 - val_loss: 6.8825e-05\n",
      "Epoch 977/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7258e-05 - val_loss: 6.8623e-05\n",
      "Epoch 978/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5574e-05 - val_loss: 6.8546e-05\n",
      "Epoch 979/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7670e-05 - val_loss: 6.8570e-05\n",
      "Epoch 980/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6762e-05 - val_loss: 6.8365e-05\n",
      "Epoch 981/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5269e-05 - val_loss: 6.8937e-05\n",
      "Epoch 982/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7263e-05 - val_loss: 6.8454e-05\n",
      "Epoch 983/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8017e-05 - val_loss: 6.8959e-05\n",
      "Epoch 984/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7915e-05 - val_loss: 6.9376e-05\n",
      "Epoch 985/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8008e-05 - val_loss: 6.8460e-05\n",
      "Epoch 986/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6332e-05 - val_loss: 6.9190e-05\n",
      "Epoch 987/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9412e-05 - val_loss: 6.9210e-05\n",
      "Epoch 988/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 7.0114e-05 - val_loss: 6.8471e-05\n",
      "Epoch 989/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8815e-05 - val_loss: 6.8613e-05\n",
      "Epoch 990/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6361e-05 - val_loss: 6.8428e-05\n",
      "Epoch 991/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7659e-05 - val_loss: 6.8902e-05\n",
      "Epoch 992/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6078e-05 - val_loss: 6.8576e-05\n",
      "Epoch 993/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.6173e-05 - val_loss: 6.9301e-05\n",
      "Epoch 994/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.5876e-05 - val_loss: 6.8790e-05\n",
      "Epoch 995/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7498e-05 - val_loss: 6.8446e-05\n",
      "Epoch 996/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7078e-05 - val_loss: 6.9264e-05\n",
      "Epoch 997/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8436e-05 - val_loss: 6.8715e-05\n",
      "Epoch 998/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.7410e-05 - val_loss: 6.9928e-05\n",
      "Epoch 999/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.8625e-05 - val_loss: 6.8856e-05\n",
      "Epoch 1000/1000\n",
      "590/590 [==============================] - 1s 1ms/step - loss: 6.9177e-05 - val_loss: 6.9418e-05\n"
     ]
    }
   ],
   "source": [
    "# train your model\n",
    "# The fit function allows you to train a NN model. Here we have training data, number of epochs,batch size, validation data, \n",
    "# and callbacks as input\n",
    "# Callback is an optional parameters that allow you to enable tricks for training such as early stopping and checkpoint\n",
    "\n",
    "# Remarks: Altough we put 50000 epochs here, the model will stop its training once our early stopping criterion is triggered\n",
    "\n",
    "history=model.fit(X_scaled_train[:,3:6],y_train,epochs=1000, batch_size = 128, verbose = 1, validation_data=(X_scaled_vals[:,3:6],y_val),\n",
    "                 callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss(MSE): 6.452001980505884e-05\n"
     ]
    }
   ],
   "source": [
    "# Load the best model you saved and calcuate MSE for testing set\n",
    "\n",
    "model = keras.models.load_model(\"implied_vol_model_vFinal.h5\")\n",
    "mse_test = model.evaluate(X_scaled_test[:,3:6],y_test,verbose=0)\n",
    "\n",
    "print('Test Loss(MSE):', mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gain Ratio: 0.1308289873334727\n"
     ]
    }
   ],
   "source": [
    "# Calculate Gain Ratio\n",
    "\n",
    "gain = 1 - mse_test/mse \n",
    "\n",
    "print('Gain Ratio:', gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review your results and export training history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training history\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0.00007,0.00015)\n",
    "plt.show()\n",
    "\n",
    "#Export your training history for MSE\n",
    "output = pd.DataFrame(history.history)\n",
    "output.to_csv(\"mse_overtime.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
